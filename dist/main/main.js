"use strict";const{app:m,BrowserWindow:y,ipcMain:l}=require("electron"),u=require("path"),P=!m.isPackaged,{exec:d,spawn:g}=require("child_process"),v=require("https"),p=require("fs"),h=require("os");let i,a;const q=()=>new Promise((e,r)=>{v.get("https://ollama.ai/install.sh",o=>{let n="";o.on("data",t=>{n+=t}),o.on("end",()=>{e(n)})}).on("error",o=>{r(o)})}),x=async()=>{const e=h.platform();if(e==="darwin"){const r=await q(),o=u.join(h.tmpdir(),"ollama-install.sh");return p.writeFileSync(o,r),p.chmodSync(o,"755"),new Promise((n,t)=>{d(`sh ${o}`,(s,c,w)=>{if(s){t(s);return}n(c)})})}else throw e==="win32"?new Error("Windows installation not yet implemented"):new Error("Unsupported platform")},k=()=>new Promise((e,r)=>{const n=h.platform()==="win32"?"ollama.exe":"ollama";a=g(n,["serve"]),a.stdout.on("data",t=>{console.log(`Ollama: ${t}`),t.toString().includes("Listening")&&e()}),a.stderr.on("data",t=>{console.error(`Ollama Error: ${t}`)}),a.on("error",t=>{r(t)})}),O=e=>new Promise((r,o)=>{const n=g("ollama",["pull",e]);n.stdout.on("data",t=>{const c=t.toString().match(/([0-9.]+)%/);if(c){const w=parseFloat(c[1]);i.webContents.send("model-pull-progress",w)}}),n.stderr.on("data",t=>{console.error(`Model Pull Error: ${t}`)}),n.on("close",t=>{t===0?r():o(new Error(`Model pull failed with code ${t}`))})});function f(){if(i=new y({width:1200,height:800,title:"Alt Text AI",icon:u.join(__dirname,"../../assets/images/icon-512.gif"),webPreferences:{nodeIntegration:!1,contextIsolation:!0,preload:u.join(__dirname,"../preload/preload.js")}}),P)i.loadURL("http://localhost:5173"),i.webContents.openDevTools();else{const e=u.join(__dirname,"../../dist/index.html");i.loadFile(e).catch(r=>{console.error("Failed to load index.html:",r),i.loadURL(`file://${e}`).catch(o=>{console.error("Failed to load using file URL:",o)})})}i.once("ready-to-show",()=>{i.show()})}l.handle("install-ollama",async()=>{try{return await x(),!0}catch(e){throw e}});l.handle("pull-model",async(e,r)=>{try{return await O(r),!0}catch(o){throw o}});l.handle("start-ollama-server",async()=>{try{return await k(),!0}catch(e){throw e}});l.handle("check-ollama-status",async()=>new Promise(e=>{d("ollama --version",r=>{e(!r)})}));l.handle("quit-app",()=>{m.quit()});m.whenReady().then(()=>{f(),m.on("activate",()=>{y.getAllWindows().length===0&&f()})});m.on("window-all-closed",()=>{process.platform!=="darwin"&&m.quit()});m.on("before-quit",()=>{a&&a.kill()});const b=()=>new Promise((e,r)=>{d("ollama --version",(o,n)=>{if(o){r(o);return}e(n.trim())})}),S=()=>new Promise((e,r)=>{const n=h.platform()==="win32"?"where ollama":"which ollama";d(n,(t,s)=>{if(t){r(t);return}e(s.trim())})}),$=()=>new Promise((e,r)=>{if(!a){e();return}a.on("close",()=>{a=null,e()}),a.kill()});l.handle("get-ollama-version",async()=>{try{return await b()}catch(e){throw e}});l.handle("get-ollama-path",async()=>{try{return await S()}catch(e){throw e}});l.handle("stop-ollama-server",async()=>{try{return await $(),!0}catch(e){throw e}});const E=async()=>new Promise((e,r)=>{const o=h.platform();let n;switch(o){case"darwin":n="open -a Terminal";break;case"win32":n="start cmd";break;case"linux":const t=["gnome-terminal","konsole","xterm"];for(const s of t)try{d(`which ${s}`,c=>{if(!c){n=s;return}})}catch{}n||(n="xterm");break;default:r(new Error("Unsupported platform"));return}d(n,t=>{if(t){r(t);return}e()})});l.handle("open-terminal",async()=>{try{return await E(),!0}catch(e){throw console.error("Failed to open terminal:",e),e}});
